{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92d93039",
   "metadata": {},
   "source": [
    "# Load Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3c4e466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "import psycopg2\n",
    "import requests\n",
    "\n",
    "EXCEL_FILE = \"source/receipe.xlsx\"\n",
    "\n",
    "# --- Configuration ---\n",
    "HASURA_ENDPOINT = \"http://localhost:8080/v1/metadata\"\n",
    "HASURA_HEADERS = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    # Add this if you have an admin secret: \"x-hasura-admin-secret\": \"your_secret\"\n",
    "}\n",
    "\n",
    "DB_URI = \"postgresql://ph_kitchen:Nathy202102!@localhost:5433/kitchendb\"\n",
    "DB_SCHEMA = \"public\"\n",
    "SOURCE_NAME = \"default\"  # Change if your Hasura source has another name\n",
    "\n",
    "# --- Init ---\n",
    "\n",
    "engine = create_engine(DB_URI)\n",
    "xlsx = pd.ExcelFile(EXCEL_FILE)\n",
    "\n",
    "table_columns = {}\n",
    "pk_candidates = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd5b40c",
   "metadata": {},
   "source": [
    "## PG Manipulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586d8e71",
   "metadata": {},
   "source": [
    "### Step 1: Upload tables and store column metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90d9be9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading 'store_section'\n",
      "Uploading 'ingredient'\n",
      "Uploading 'unit'\n",
      "Uploading 'meal'\n",
      "Uploading 'website'\n",
      "Uploading 'book'\n",
      "Uploading 'recipe'\n",
      "Uploading 'link'\n",
      "Uploading 'map_recipe_link'\n",
      "Uploading 'map_recipe_book'\n",
      "Uploading 'map_recipe_ingredient'\n"
     ]
    }
   ],
   "source": [
    "for sheet in xlsx.sheet_names:\n",
    "    df = xlsx.parse(sheet)\n",
    "    table = sheet.lower().replace(\" \", \"_\")\n",
    "\n",
    "    print(f\"Uploading '{table}'\")\n",
    "    df.to_sql(table, con=engine, index=False, if_exists='replace')\n",
    "\n",
    "    cols = [c.lower() for c in df.columns]\n",
    "    table_columns[table] = cols\n",
    "\n",
    "    # Primary key candidate: table_name + '_id'\n",
    "    expected_pk = f\"{table}_id\"\n",
    "    if expected_pk in cols:\n",
    "        pk_candidates[table] = expected_pk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0067fbdd",
   "metadata": {},
   "source": [
    "### Step 2: Add primary keys (if not added by default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d6751a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.begin() as conn:\n",
    "    for table, pk in pk_candidates.items():\n",
    "        # print(f\"Adding PRIMARY KEY on {table}({pk})\")\n",
    "        sql_command=text(f\"\"\"\n",
    "            ALTER TABLE {table}\n",
    "            ADD PRIMARY KEY ({pk})\n",
    "        \"\"\")\n",
    "        # print(sql_command)\n",
    "        conn.execute(sql_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3441016",
   "metadata": {},
   "source": [
    "### Step 3: Add foreign keys based on *_id pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e913ced2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding FK: ingredient.store_section_id → store_section.store_section_id\n",
      "Adding FK: unit.ingredient_id → ingredient.ingredient_id\n",
      "Adding FK: link.website_id → website.website_id\n",
      "Adding FK: map_recipe_link.recipe_id → recipe.recipe_id\n",
      "Adding FK: map_recipe_link.link_id → link.link_id\n",
      "Adding FK: map_recipe_book.recipe_id → recipe.recipe_id\n",
      "Adding FK: map_recipe_book.book_id → book.book_id\n",
      "Adding FK: map_recipe_ingredient.recipe_id → recipe.recipe_id\n",
      "Adding FK: map_recipe_ingredient.ingredient_id → ingredient.ingredient_id\n",
      "Adding FK: map_recipe_ingredient.unit_id → unit.unit_id\n"
     ]
    }
   ],
   "source": [
    "with engine.begin() as conn:\n",
    "    for table, columns in table_columns.items():\n",
    "        for col in columns:\n",
    "            if col.endswith(\"_id\") and col != pk_candidates.get(table, \"\"):\n",
    "                ref_table = col[:-3]  # e.g., customer_id → customer\n",
    "                possible_ref = ref_table + \"_id\"\n",
    "                for t, pk in pk_candidates.items():\n",
    "                    if pk == possible_ref:\n",
    "                        fk_name = f\"{table}_{col}_fkey\"\n",
    "                        print(f\"Adding FK: {table}.{col} → {t}.{pk}\")\n",
    "                        conn.execute(text(f\"\"\"\n",
    "                            ALTER TABLE {table}\n",
    "                            ADD CONSTRAINT {fk_name}\n",
    "                            FOREIGN KEY ({col})\n",
    "                            REFERENCES {t}({pk})\n",
    "                            ON DELETE SET NULL\n",
    "                        \"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77742ad1",
   "metadata": {},
   "source": [
    "## Hasura Manipulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fbab1c",
   "metadata": {},
   "source": [
    "### Track all tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6b2fb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11 tables: ['meal', 'store_section', 'ingredient', 'unit', 'website', 'link', 'recipe', 'map_recipe_link', 'map_recipe_book', 'book', 'map_recipe_ingredient']\n",
      "✅ All tables tracked successfully!\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Get all tables from Postgres ---\n",
    "conn = psycopg2.connect(DB_URI)\n",
    "cur = conn.cursor()\n",
    "cur.execute(f\"\"\"\n",
    "    SELECT tablename\n",
    "    FROM pg_tables\n",
    "    WHERE schemaname = %s\n",
    "\"\"\", (DB_SCHEMA,))\n",
    "table_names = [row[0] for row in cur.fetchall()]\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "print(f\"Found {len(table_names)} tables: {table_names}\")\n",
    "\n",
    "# --- Step 2: Prepare Hasura bulk tracking payload ---\n",
    "bulk_payload = {\n",
    "    \"type\": \"bulk\",\n",
    "    \"args\": [\n",
    "        {\n",
    "            \"type\": \"pg_track_table\",\n",
    "            \"args\": {\n",
    "                \"source\": SOURCE_NAME,\n",
    "                \"table\": {\n",
    "                    \"schema\": DB_SCHEMA,\n",
    "                    \"name\": table_name\n",
    "                }\n",
    "            }\n",
    "        } for table_name in table_names\n",
    "    ]\n",
    "}\n",
    "\n",
    "# --- Step 3: Send request to Hasura ---\n",
    "response = requests.post(HASURA_ENDPOINT, json=bulk_payload, headers=HASURA_HEADERS)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(\"✅ All tables tracked successfully!\")\n",
    "else:\n",
    "    print(f\"❌ Error tracking tables: {response.status_code}\")\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6970f3a",
   "metadata": {},
   "source": [
    "### Add Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c3e24fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 foreign key(s)\n",
      "✅ Relationships created successfully!\n"
     ]
    }
   ],
   "source": [
    "# --- Step 1: Get Foreign Key Constraints ---\n",
    "def get_foreign_keys():\n",
    "    conn = psycopg2.connect(DB_URI)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT\n",
    "            tc.table_name AS from_table,\n",
    "            kcu.column_name AS from_column,\n",
    "            ccu.table_name AS to_table,\n",
    "            ccu.column_name AS to_column,\n",
    "            tc.constraint_name\n",
    "        FROM information_schema.table_constraints AS tc\n",
    "        JOIN information_schema.key_column_usage AS kcu\n",
    "            ON tc.constraint_name = kcu.constraint_name\n",
    "        JOIN information_schema.constraint_column_usage AS ccu\n",
    "            ON ccu.constraint_name = tc.constraint_name\n",
    "        WHERE tc.constraint_type = 'FOREIGN KEY' AND tc.table_schema = %s\n",
    "    \"\"\", (DB_SCHEMA,))\n",
    "    fks = cur.fetchall()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    return fks\n",
    "\n",
    "# --- Step 2: Format Relationship Payloads ---\n",
    "def build_relationships_payload(fks):\n",
    "    bulk_payload = { \"type\": \"bulk\", \"args\": [] }\n",
    "    for from_table, from_col, to_table, to_col, constraint_name in fks:\n",
    "        # Object relationship (from_table -> to_table)\n",
    "        object_rel = {\n",
    "            \"type\": \"pg_create_object_relationship\",\n",
    "            \"args\": {\n",
    "                \"source\": SOURCE_NAME,\n",
    "                \"table\": {\n",
    "                    \"schema\": DB_SCHEMA,\n",
    "                    \"name\": from_table\n",
    "                },\n",
    "                \"name\": f\"{to_table}_by_{from_col}\",\n",
    "                \"using\": {\n",
    "                    \"foreign_key_constraint_on\": from_col\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Array relationship (to_table -> from_table)\n",
    "        array_rel = {\n",
    "            \"type\": \"pg_create_array_relationship\",\n",
    "            \"args\": {\n",
    "                \"source\": SOURCE_NAME,\n",
    "                \"table\": {\n",
    "                    \"schema\": DB_SCHEMA,\n",
    "                    \"name\": to_table\n",
    "                },\n",
    "                \"name\": f\"{from_table}_set\",\n",
    "                \"using\": {\n",
    "                    \"foreign_key_constraint_on\": {\n",
    "                        \"table\": {\n",
    "                            \"schema\": DB_SCHEMA,\n",
    "                            \"name\": from_table\n",
    "                        },\n",
    "                        \"column\": from_col\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        bulk_payload[\"args\"].extend([object_rel, array_rel])\n",
    "    return bulk_payload\n",
    "\n",
    "# --- Step 3: Send to Hasura ---\n",
    "def send_to_hasura(payload):\n",
    "    res = requests.post(HASURA_ENDPOINT, json=payload, headers=HASURA_HEADERS)\n",
    "    if res.status_code == 200:\n",
    "        print(\"✅ Relationships created successfully!\")\n",
    "    else:\n",
    "        print(f\"❌ Failed to create relationships: {res.status_code}\")\n",
    "        print(res.text)\n",
    "\n",
    "# --- Run it ---\n",
    "fks = get_foreign_keys()\n",
    "print(f\"Found {len(fks)} foreign key(s)\")\n",
    "payload = build_relationships_payload(fks)\n",
    "send_to_hasura(payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44709aa6",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
